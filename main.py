import time
import re
import json
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
import arabic_reshaper
from bidi.algorithm import get_display
from urllib.parse import urljoin, quote
from deep_translator import GoogleTranslator

# -------------------- Basic translation settings --------------------
TRANSLATION_DICT = {
    # Fuel types
    'ÙƒÙ‡Ø±Ø¨Ø§Ø¡': 'Electric',
    'Ù‡Ø§ÙŠØ¨Ø±Ø¯': 'Hybrid',
    'Ø¨Ù†Ø²ÙŠÙ†': 'Petrol',
    'Ø¯ÙŠØ²Ù„': 'Diesel',
    # Car condition
    'Ø¬Ø¯ÙŠØ¯ (Ø²ÙŠØ±Ùˆ)': 'New (Zero)',
    'Ù…Ø³ØªØ¹Ù…Ù„': 'Used',
    # Seller type
    'Ø´Ø®ØµÙŠ': 'Private',
    'Ù…Ø¹Ø±Ø¶': 'Dealer',
    'ÙˆÙƒØ§Ù„Ø©': 'Agency',
    'Ù…Ø¹Ø±Ø¶/ÙˆÙƒØ§Ù„Ø©': 'Dealer/Agency',
    # Insurance
    'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†': 'No Insurance',
    'ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†': 'Insured',
    'ØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„': 'Comprehensive Insurance',
    'ØªØ£Ù…ÙŠÙ† Ø¥Ù„Ø²Ø§Ù…ÙŠ': 'Mandatory Insurance',
    'Ù…ÙƒÙÙˆÙ„Ø©': 'Warranty Included',
    # Cities
    'Ø¹Ù…Ø§Ù†': 'Amman',
    'Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡': 'Zarqa',
    'Ø¥Ø±Ø¨Ø¯': 'Irbid',
    'Ø§Ù„Ø¨Ù„Ù‚Ø§Ø¡': 'Balqa',
    'Ø§Ù„Ù…ÙØ±Ù‚': 'Mafraq',
    'Ø¬Ø±Ø´': 'Jerash',
    'Ù…Ø§Ø¯Ø¨Ø§': 'Madaba',
    'Ø§Ù„ÙƒØ±Ùƒ': 'Karak',
    'Ø§Ù„Ø·ÙÙŠÙ„Ø©': 'Tafila',
    'Ù…Ø¹Ø§Ù†': 'Ma\'an',
    'Ø§Ù„Ø¹Ù‚Ø¨Ø©': 'Aqaba',
    'Ø¹Ø¬Ù„ÙˆÙ†': 'Ajloun',
    'Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø­Ø±Ø©': 'Free Zone',
    # Transmission
    'Ø§ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ': 'Automatic',
    'ÙŠØ¯ÙˆÙŠ': 'Manual',
    'Ø§ØªÙˆÙ…Ø§ØªÙŠÙƒ': 'Automatic',
    # Colors
    'Ø£Ø¨ÙŠØ¶': 'White',
    'Ø£Ø³ÙˆØ¯': 'Black',
    'Ø±Ù…Ø§Ø¯ÙŠ': 'Gray',
    'ÙØ¶ÙŠ': 'Silver',
    'Ø£Ø²Ø±Ù‚': 'Blue',
    'Ø£Ø­Ù…Ø±': 'Red',
    'Ø£Ø®Ø¶Ø±': 'Green',
    'Ø¨Ù†ÙŠ': 'Brown',
    'Ø¨ÙŠØ¬': 'Beige',
    'Ø°Ù‡Ø¨ÙŠ': 'Gold',
    'Ø£Ø²Ø±Ù‚ ÙØ§ØªØ­': 'Light Blue',
    # Default values
    'ØºÙŠØ± Ù…Ø­Ø¯Ø¯': 'Not Specified',
    'ØºÙŠØ± Ù…ØªÙˆÙØ±': 'N/A',
    'Ù†Ø¹Ù…': 'Yes',
    'Ù„Ø§': 'No',
}

# -------------------- Comprehensive brand and model dictionaries --------------------
BRAND_TRANSLATION = {
    # Japanese brands
    'ØªÙˆÙŠÙˆØªØ§': 'Toyota',
    'Ù‡ÙˆÙ†Ø¯Ø§': 'Honda',
    'Ù†ÙŠØ³Ø§Ù†': 'Nissan',
    'Ù…ÙŠØªØ³ÙˆØ¨ÙŠØ´ÙŠ': 'Mitsubishi',
    'Ù…Ø§Ø²Ø¯Ø§': 'Mazda',
    'ÙƒÙŠØ§': 'Kia',
    'Ù‡ÙŠÙˆÙ†Ø¯Ø§ÙŠ': 'Hyundai',
    'Ø³ÙˆØ¨Ø§Ø±Ùˆ': 'Subaru',
    'Ø³ÙˆØ²ÙˆÙƒÙŠ': 'Suzuki',
    'Ø¯ÙŠÙ‡Ø§ØªØ³Ùˆ': 'Daihatsu',
    'Ø§ÙŠØ³ÙˆØ²Ùˆ': 'Isuzu',
    'Ù„ÙƒØ²Ø³': 'Lexus',
    'Ø§Ù†ÙÙŠÙ†ÙŠØªÙŠ': 'Infiniti',
    # German brands
    'Ù…Ø±Ø³ÙŠØ¯Ø³': 'Mercedes-Benz',
    'Ø¨ÙŠ Ø§Ù… Ø¯Ø¨Ù„ÙŠÙˆ': 'BMW',
    'Ø£ÙˆØ¯ÙŠ': 'Audi',
    'ÙÙˆÙ„ÙƒØ³ ÙØ§Ø¬Ù†': 'Volkswagen',
    'Ø¨ÙˆØ±Ø´': 'Porsche',
    'Ø£ÙˆØ¨Ù„': 'Opel',
    # American brands
    'ÙÙˆØ±Ø¯': 'Ford',
    'Ø´ÙŠÙØ±ÙˆÙ„ÙŠÙ‡': 'Chevrolet',
    'Ø¬ÙŠØ¨': 'Jeep',
    'ÙƒØ§Ø¯ÙŠÙ„Ø§Ùƒ': 'Cadillac',
    'ÙƒØ±Ø§ÙŠØ³Ù„Ø±': 'Chrysler',
    'Ø¯ÙˆØ¯Ø¬': 'Dodge',
    'Ø±Ø§Ù…': 'Ram',
    'Ø¬Ù…Ø³': 'GMC',
    'Ù„ÙŠÙ†ÙƒÙˆÙ„Ù†': 'Lincoln',
    # British brands
    'Ø±Ù†Ø¬ Ø±ÙˆÙØ±': 'Range Rover',
    'Ù„Ø§Ù†Ø¯ Ø±ÙˆÙØ±': 'Land Rover',
    'Ø¬Ø§ØºÙˆØ§Ø±': 'Jaguar',
    'Ù…ÙŠÙ†ÙŠ': 'Mini',
    'Ø¨Ù†ØªÙ„ÙŠ': 'Bentley',
    'Ø±ÙˆÙ„Ø² Ø±ÙˆÙŠØ³': 'Rolls-Royce',
    'Ø§Ø³ØªÙˆÙ† Ù…Ø§Ø±ØªÙ†': 'Aston Martin',
    'Ù…Ø§ÙƒÙ„Ø§Ø±ÙŠÙ†': 'McLaren',
    # Italian brands
    'ÙÙŠØ§Øª': 'Fiat',
    'Ø£Ù„ÙØ§ Ø±ÙˆÙ…ÙŠÙˆ': 'Alfa Romeo',
    'Ù…Ø§Ø²ÙŠØ±Ø§ØªÙŠ': 'Maserati',
    'Ù„ÙˆØªØ³': 'Lotus',
    'Ù„Ø§Ù…Ø¨ÙˆØ±ØºÙŠÙ†ÙŠ': 'Lamborghini',
    'ÙÙŠØ±Ø§Ø±ÙŠ': 'Ferrari',
    # French brands
    'Ø±ÙŠÙ†Ùˆ': 'Renault',
    'Ø¨ÙŠØ¬Ùˆ': 'Peugeot',
    'Ø³ÙŠØªØ±ÙˆÙŠÙ†': 'CitroÃ«n',
    'Ø¯Ø§Ø³ÙŠØ§': 'Dacia',
    # Chinese brands
    'Ø¨ÙŠ ÙˆØ§ÙŠ Ø¯ÙŠ': 'BYD',
    'Ø§Ù… Ø¬ÙŠ': 'MG',
    'Ø¬Ø§Ùƒ': 'JAC',
    'Ù‡Ø§ÙØ§Ù„': 'Haval',
    'Ø´Ø§Ù†Ø¬Ø§Ù†': 'Changan',
    'Ø¬ÙŠÙ„ÙŠ': 'Geely',
    'Ø´ÙŠØ±ÙŠ': 'Chery',
    'Ù†ÙŠØªØ§': 'Neta',
    'Ø¨Ø±ÙˆØªÙˆÙ†': 'Proton',
    # Other brands
    'ØªÙŠØ³Ù„Ø§': 'Tesla',
    'ÙÙˆÙ„ÙÙˆ': 'Volvo',
}

MODEL_TRANSLATION = {
    # Toyota
    'ÙƒØ§Ù…Ø±ÙŠ': 'Camry',
    'ÙƒÙˆØ±ÙˆÙ„Ø§': 'Corolla',
    'ÙŠØ§Ø±Ø³': 'Yaris',
    'Ø±Ø§Ù ÙÙˆØ±': 'RAV4',
    'Ù‡ÙŠÙ„ÙˆÙƒØ³': 'Hilux',
    'Ù„Ø§Ù†Ø¯ ÙƒØ±ÙˆØ²Ø±': 'Land Cruiser',
    'Ø¨Ø±Ø§Ø¯Ùˆ': 'Prado',
    'Ø§ÙØ§Ù„ÙˆÙ†': 'Avalon',
    'Ø³ÙˆØ¨Ø±Ø§': 'Supra',
    # Honda
    'Ø³ÙŠÙÙŠÙƒ': 'Civic',
    'Ø§ÙƒÙˆØ±Ø¯': 'Accord',
    'Ø³ÙŠ Ø§Ø± ÙÙŠ': 'CR-V',
    'Ø§ØªØ´ Ø§Ø± ÙÙŠ': 'HR-V',
    'Ø¨Ø§ÙŠÙ„ÙˆØª': 'Pilot',
    # Nissan
    'Ø³Ù†ØªØ±Ø§': 'Sentra',
    'Ø§Ù„ØªÙŠÙ…Ø§': 'Altima',
    'Ù…Ø§ÙƒØ³ÙŠÙ…Ø§': 'Maxima',
    'Ø¨Ø§ØªØ±ÙˆÙ„': 'Patrol',
    'Ù‚Ø´Ù‚Ø§ÙŠ': 'Qashqai',
    # Hyundai
    'Ø³ÙˆÙ†Ø§ØªØ§': 'Sonata',
    'Ø§Ù„Ù†ØªØ±Ø§': 'Elantra',
    'Ø§ÙØ§Ù†ØªÙŠ': 'Elantra',
    'Ø§ÙƒØ³Ù†Øª': 'Accent',
    'ØªÙˆØ³Ø§Ù†': 'Tucson',
    'Ø³Ø§Ù†ØªØ§ÙÙŠ': 'Santa Fe',
    'Ø§Ø²ÙŠØ±Ø§': 'Azera',
    # Kia
    'Ø³Ø¨ÙˆØ±ØªØ§Ø¬': 'Sportage',
    'Ø³ÙˆØ±ÙŠÙ†ØªÙˆ': 'Sorento',
    'Ø§ÙˆØ¨ØªÙŠÙ…Ø§': 'Optima',
    'ÙƒØ§Ø¯ÙŠÙ†Ø²Ø§': 'Cadenza',
    'Ø±ÙŠÙˆ': 'Rio',
    'Ø³ÙˆÙ„': 'Soul',
    # Mercedes
    'Ø§Ù„ÙØ¦Ø©-Ø³ÙŠ': 'C-Class',
    'Ø§Ù„ÙØ¦Ø©-Ø§ÙŠ': 'E-Class',
    'Ø§Ù„ÙØ¦Ø©-Ø§Ø³': 'S-Class',
    'Ø¬ÙŠ Ø§Ù„ Ø§ÙŠ': 'GLE',
    'Ø¬ÙŠ Ø§Ù„ Ø³ÙŠ': 'GLC',
    'Ø§ÙŠÙ‡ Ø§Ù… Ø¬ÙŠ': 'AMG',
    # BMW
    'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©': '3 Series',
    'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø®Ø§Ù…Ø³Ø©': '5 Series',
    'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø³Ø§Ø¨Ø¹Ø©': '7 Series',
    'Ø§ÙƒØ³ 1': 'X1',
    'Ø§ÙƒØ³ 3': 'X3',
    'Ø§ÙƒØ³ 5': 'X5',
    # Audi
    'Ø§ÙŠÙ‡ 3': 'A3',
    'Ø§ÙŠÙ‡ 4': 'A4',
    'Ø§ÙŠÙ‡ 6': 'A6',
    'Ø§ÙŠÙ‡ 8': 'A8',
    'ÙƒÙŠÙˆ 2': 'Q2',
    'ÙƒÙŠÙˆ 3': 'Q3',
    'ÙƒÙŠÙˆ 5': 'Q5',
    'ÙƒÙŠÙˆ 7': 'Q7',
    # Ford
    'ÙÙˆÙƒØ³': 'Focus',
    'ÙÙŠÙˆØ¬Ù†': 'Fusion',
    'Ù…ÙˆØ³ØªØ§Ù†Ø¬': 'Mustang',
    'Ø§Ù-150': 'F-150',
    'Ø§ÙƒØ³Ø¨Ù„ÙˆØ±Ø±': 'Explorer',
    # Chevrolet
    'Ù…Ø§Ù„ÙŠØ¨Ùˆ': 'Malibu',
    'ÙƒØ§Ù…Ø§Ø±Ùˆ': 'Camaro',
    'ÙƒÙˆØ±ÙÙŠØª': 'Corvette',
    'Ø³ÙŠÙ„ÙØ±Ø§Ø¯Ùˆ': 'Silverado',
    'ØªØ§Ù‡Ùˆ': 'Tahoe',
    # Tesla
    'Ù…ÙˆØ¯ÙŠÙ„ 3': 'Model 3',
    'Ù…ÙˆØ¯ÙŠÙ„ Ø§Ø³': 'Model S',
    'Ù…ÙˆØ¯ÙŠÙ„ Ø§ÙƒØ³': 'Model X',
    'Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§ÙŠ': 'Model Y',
    # Other common models
    'Ø¨Ø§Ù†Ø§Ù…ÙŠØ±Ø§': 'Panamera',
    'ÙƒØ§ÙŠÙŠÙ†': 'Cayenne',
    'Ù…Ø§ÙƒØ§Ù†': 'Macan',
    'Ø¬ÙˆÙ„Ù': 'Golf',
    'Ø¨Ø§Ø³Ø§Øª': 'Passat',
    'Ù„ÙˆØ¬Ø§Ù†': 'Logan',
    'Ø¯Ø§Ø³ØªØ±': 'Duster',
    'Ø³Ø§Ù†Ø¯ÙŠØ±Ùˆ': 'Sandero',
}

# Trim keywords
TRIM_KEYWORDS = {
    'Standard': ['standard', 'base', 'Ø§Ø³Ø§Ø³ÙŠ', 'Ù‚ÙŠØ§Ø³ÙŠ'],
    'Sport': ['sport', 'spt', 'Ø±ÙŠØ§Ø¶ÙŠ'],
    'Luxury': ['luxury', 'lux', 'ÙØ§Ø®Ø±'],
    'Premium': ['premium', 'Ø¨Ø±ÙŠÙ…ÙŠÙˆÙ…'],
    'Limited': ['limited', 'Ù„ÙŠÙ…ØªØ¯', 'Ù…Ø­Ø¯ÙˆØ¯'],
    'Platinum': ['platinum', 'Ø¨Ù„Ø§ØªÙŠÙ†ÙŠÙˆÙ…'],
    'Titanium': ['titanium', 'ØªÙŠØªØ§Ù†ÙŠÙˆÙ…'],
    'SEL': ['sel'],
    'SE': ['se'],
    'LE': ['le'],
    'XLE': ['xle'],
    'XE': ['xe'],
    'GT': ['gt'],
    'GTE': ['gte'],
    'Plus': ['plus', 'Ø¨Ù„Ø³'],
    'Pro': ['pro', 'Ø¨Ø±Ùˆ'],
}

# List of brands for model extraction
CAR_BRANDS = list(BRAND_TRANSLATION.keys())

# -------------------- Smart model translation functions --------------------
def search_car_model_online(car_name):
    """
    Search for car model translation online (Wikipedia)
    """
    try:
        search_query = quote(f"{car_name} car")
        url = f"https://en.wikipedia.org/wiki/{search_query.replace(' ', '_')}"
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=5)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            title = soup.find('h1', {'id': 'firstHeading'})
            if title:
                return title.text.strip()
    except:
        pass
    return None

def split_car_model(text):
    """
    Split car name into parts: brand, model, trim
    """
    text = text.strip()
    original = text
    brand = None
    model = None
    trim = []
    remaining = []

    # Search for brand
    for ar_brand in BRAND_TRANSLATION.keys():
        if ar_brand in text:
            brand = ar_brand
            text = text.replace(ar_brand, '', 1).strip()
            break

    # Search for model
    words = text.split()
    for word in words:
        found = False
        for ar_model in MODEL_TRANSLATION.keys():
            if ar_model in word or word in ar_model:
                model = ar_model
                text = text.replace(ar_model, '', 1).strip()
                found = True
                break
        if found:
            break

    # Search for trim keywords
    words = text.split()
    for word in words:
        word_lower = word.lower()
        matched = False
        for trim_name, keywords in TRIM_KEYWORDS.items():
            if word_lower in keywords or any(kw in word_lower for kw in keywords):
                trim.append(trim_name)
                text = text.replace(word, '', 1).strip()
                matched = True
                break
        if not matched:
            remaining.append(word)

    # Clean up remaining text
    extra = ' '.join(remaining).strip()
    if extra and not model:
        model = extra
        extra = ''

    return {
        'brand': brand,
        'model': model,
        'trim': ' '.join(trim) if trim else None,
        'extra': extra if extra else None
    }

def translate_car_model_smart(text):
    """
    Smart translation of car names using dictionaries and online search.
    """
    if not isinstance(text, str) or text.strip() == '':
        return text
    original = text.strip()

    # Parse the name
    parts = split_car_model(original)

    translated_parts = []

    # Translate brand
    if parts['brand']:
        translated_parts.append(BRAND_TRANSLATION.get(parts['brand'], parts['brand']))

    # Translate model
    if parts['model']:
        if parts['model'] in MODEL_TRANSLATION:
            translated_parts.append(MODEL_TRANSLATION[parts['model']])
        else:
            # Try online search
            online = search_car_model_online(parts['model'])
            if online:
                translated_parts.append(online)
            else:
                translated_parts.append(parts['model'])  # keep as is

    # Add trim
    if parts['trim']:
        translated_parts.append(parts['trim'])

    # Add extra text
    if parts['extra']:
        # If it contains Arabic, translate it normally
        if any('\u0600' <= c <= '\u06FF' for c in parts['extra']):
            translated_parts.append(translate_text_fallback(parts['extra']))
        else:
            translated_parts.append(parts['extra'])

    # If nothing was translated, return original
    if not translated_parts:
        return original

    return ' '.join(translated_parts)

def translate_text_fallback(text, target='en'):
    """Translate plain text using dictionary or automatic translation."""
    if text in TRANSLATION_DICT:
        return TRANSLATION_DICT[text]
    try:
        translated = GoogleTranslator(source='ar', target=target).translate(text)
        if translated and translated != text:
            return translated
    except:
        pass
    return text

def translate_text(text, target='en'):
    # General function for other texts (not model)
    return translate_text_fallback(text, target)

def fix_arabic(text):
    """Reshape Arabic text for proper display."""
    if isinstance(text, str) and any("\u0600" <= c <= "\u06FF" for c in text):
        try:
            reshaped_text = arabic_reshaper.reshape(text)
            return get_display(reshaped_text)
        except:
            return text
    return text

# -------------------- Basic data extraction functions --------------------
def convert_arabic_numbers(text):
    """Convert Arabic numerals (e.g., Ù¡Ù¢Ù£) to Western numbers (123)."""
    arabic_nums = str.maketrans('Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©', '0123456789')
    return text.translate(arabic_nums)

def extract_year(text):
    text = convert_arabic_numbers(text)
    matches = re.findall(r'\b(19[0-9]{2}|20[0-9]{2})\b', text)
    for match in matches:
        year = int(match)
        if 1900 <= year <= 2025:
            return match
    return "N/A"

def extract_mileage(text):
    text = convert_arabic_numbers(text)
    patterns = [
        r'(\d+[,.]?\d*\s*-\s*\d+[,.]?\d*)\s*(ÙƒÙ…|ÙƒÙŠÙ„ÙˆÙ…ØªØ±|km)',
        r'(\+?\d+[,.]?\d*)\s*(ÙƒÙ…|ÙƒÙŠÙ„ÙˆÙ…ØªØ±|km)'
    ]
    for pattern in patterns:
        match = re.search(pattern, text, re.I)
        if match:
            return match.group(0)
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_condition(text):
    if re.search(r'(Ø¬Ø¯ÙŠØ¯|Ø²ÙŠØ±Ùˆ|zero|ÙˆÙƒØ§Ù„Ø©|new)', text, re.I):
        return "Ø¬Ø¯ÙŠØ¯ (Ø²ÙŠØ±Ùˆ)"
    elif re.search(r'(Ù…Ø³ØªØ¹Ù…Ù„|used)', text, re.I):
        return "Ù…Ø³ØªØ¹Ù…Ù„"
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_seller_type(card):
    try:
        badge = card.find_element(By.CSS_SELECTOR, "div.memberBadge")
        badge_text = badge.text
        if "Ù…Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ«Ù‚" in badge_text:
            return "Ø´Ø®ØµÙŠ"
        elif "Ù†Ø´Ø§Ø· ØªØ¬Ø§Ø±ÙŠ Ù…ÙˆØ«Ù‚" in badge_text:
            return "Ù…Ø¹Ø±Ø¶/ÙˆÙƒØ§Ù„Ø©"
    except:
        pass
    text = card.text
    if re.search(r'(Ù…Ø¹Ø±Ø¶|dealership)', text, re.I):
        return "Ù…Ø¹Ø±Ø¶"
    elif re.search(r'(ÙˆÙƒØ§Ù„Ø©|agency)', text, re.I):
        return "ÙˆÙƒØ§Ù„Ø©"
    elif re.search(r'(Ø´Ø®ØµÙŠ|private|Ù…Ø§Ù„Ùƒ)', text, re.I):
        return "Ø´Ø®ØµÙŠ"
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_json_ld(html):
    try:
        pattern = r'<script type="application/ld\+json">(.*?)</script>'
        scripts = re.findall(pattern, html, re.DOTALL)
        for script in scripts:
            try:
                data = json.loads(script)
                if isinstance(data, dict) and data.get('@type') == 'Vehicle':
                    return data
                elif isinstance(data, list):
                    for item in data:
                        if item.get('@type') == 'Vehicle':
                            return item
            except:
                continue
    except:
        pass
    return None

# -------------------- Enhanced model extraction functions --------------------
def extract_model_from_card_and_page(card, page_html=None, page_driver=None):
    # 1. JSON-LD
    if page_html:
        json_data = extract_json_ld(page_html)
        if json_data:
            if 'name' in json_data and json_data['name']:
                return json_data['name']
            if 'model' in json_data and json_data['model']:
                return json_data['model']
    # 2. h1 from details page
    if page_driver:
        try:
            h1 = page_driver.find_element(By.CSS_SELECTOR, "h1")
            h1_text = h1.text.strip()
            if h1_text:
                return h1_text
        except:
            pass
    # 3. h2 on card
    try:
        h2 = card.find_element(By.CSS_SELECTOR, "h2.breakWord.trimTwoLines.font-20, h2.breakWord, h2")
        h2_text = h2.text.strip()
        if h2_text:
            return h2_text
    except:
        pass
    # 4. First line of card text
    card_text = card.text
    lines = [line.strip() for line in card_text.split('\n') if line.strip()]
    if lines:
        return lines[0]
    # 5. Fallback to text analysis
    return extract_brand_model_from_text(card_text)

def extract_brand_model_from_text(text):
    text = text.strip()
    found_brand = None
    for brand in CAR_BRANDS:
        if brand in text:
            found_brand = brand
            break
    if found_brand:
        rest = text.replace(found_brand, '', 1).strip()
        rest = re.sub(r'\b(Ù„Ù„Ø¨ÙŠØ¹|Ø³ÙŠØ§Ø±Ø©|Ø¨Ø­Ø§Ù„Ø©|Ù†Ø¸ÙŠÙ|Ù…Ø³ØªØ¹Ù…Ù„|Ø¬Ø¯ÙŠØ¯|Ø²ÙŠØ±Ùˆ|ÙˆÙƒØ§Ù„Ø©|Ù…Ø¹Ø±Ø¶|Ø´Ø®ØµÙŠ|ÙØ­Øµ|ÙƒØ§Ù…Ù„|Ù…Ù…ØªØ§Ø²Ø©|Ø¹Ø¯Ø§Ø¯|Ù‚Ù„ÙŠÙ„|ÙÙ„|ÙƒØ§Ø´|Ø§Ù‚Ø³Ø§Ø·|Ø¨Ø¯ÙˆÙ†|Ø¬Ù…Ø±Ùƒ|Ù„Ù‚Ø·Ø©|Ù…Ø§Ù„Ùƒ|Ø´Ø±ÙƒÙ‡|Ø§Ù„ÙˆÙƒØ§Ù„Ù‡|Ù†Ø¸ÙŠÙØ©|Ø§Ø³ØªØ®Ø¯Ø§Ù…)\b', '', rest, flags=re.I)
        rest = re.sub(r'\s+', ' ', rest).strip()
        if rest:
            return f"{found_brand} {rest}"
        else:
            return found_brand
    cleaned = re.sub(r'\b(Ù„Ù„Ø¨ÙŠØ¹|Ø³ÙŠØ§Ø±Ø©|Ø¨Ø­Ø§Ù„Ø©|Ù†Ø¸ÙŠÙ|Ù…Ø³ØªØ¹Ù…Ù„|Ø¬Ø¯ÙŠØ¯|Ø²ÙŠØ±Ùˆ|ÙˆÙƒØ§Ù„Ø©|Ù…Ø¹Ø±Ø¶|Ø´Ø®ØµÙŠ|ÙØ­Øµ|ÙƒØ§Ù…Ù„|Ù…Ù…ØªØ§Ø²Ø©|Ø¹Ø¯Ø§Ø¯|Ù‚Ù„ÙŠÙ„|ÙÙ„|ÙƒØ§Ø´|Ø§Ù‚Ø³Ø§Ø·|Ø¨Ø¯ÙˆÙ†|Ø¬Ù…Ø±Ùƒ|Ù„Ù‚Ø·Ø©|Ù…Ø§Ù„Ùƒ|Ø´Ø±ÙƒÙ‡)\b', '', text, flags=re.I)
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned if cleaned else "ØºÙŠØ± Ù…ØªÙˆÙØ±"

# -------------------- Enhanced fuel type extraction --------------------
def extract_fuel_type_advanced(driver):
    json_data = extract_json_ld(driver.page_source)
    page_text = driver.find_element(By.TAG_NAME, "body").text.lower()
    if json_data and 'fuelType' in json_data:
        fuel = json_data['fuelType'].lower()
        if 'electric' in fuel:
            return "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"
        elif 'hybrid' in fuel:
            return "Ù‡Ø§ÙŠØ¨Ø±Ø¯"
        elif 'diesel' in fuel:
            return "Ø¯ÙŠØ²Ù„"
        elif 'petrol' in fuel or 'gasoline' in fuel:
            return "Ø¨Ù†Ø²ÙŠÙ†"
    try:
        fuel_elem = driver.find_element(By.XPATH, "//span[contains(text(),'Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚ÙˆØ¯')]/following-sibling::a")
        fuel_text = fuel_elem.text.strip()
        if fuel_text:
            if 'ÙƒÙ‡Ø±Ø¨Ø§Ø¡' in fuel_text:
                return "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"
            elif 'Ù‡Ø§ÙŠØ¨Ø±Ø¯' in fuel_text:
                return "Ù‡Ø§ÙŠØ¨Ø±Ø¯"
            elif 'Ø¯ÙŠØ²Ù„' in fuel_text:
                return "Ø¯ÙŠØ²Ù„"
            elif 'Ø¨Ù†Ø²ÙŠÙ†' in fuel_text:
                return "Ø¨Ù†Ø²ÙŠÙ†"
    except:
        pass
    if re.search(r'\b(Ù‡Ø§ÙŠØ¨Ø±Ø¯|hybrid)\b', page_text, re.I):
        return "Ù‡Ø§ÙŠØ¨Ø±Ø¯"
    if re.search(r'\b(Ø¯ÙŠØ²Ù„|diesel)\b', page_text, re.I):
        return "Ø¯ÙŠØ²Ù„"
    if re.search(r'\b(Ø¨Ù†Ø²ÙŠÙ†|petrol|gasoline)\b', page_text, re.I):
        return "Ø¨Ù†Ø²ÙŠÙ†"
    if re.search(r'\b(ÙƒÙ‡Ø±Ø¨Ø§Ø¡|electric|ev)\b', page_text, re.I):
        return "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

# -------------------- Price extraction and advanced installment detection --------------------
def clean_price_number(price_str):
    if not isinstance(price_str, str) or price_str == "N/A":
        return np.nan
    match = re.search(r'(\d+[,.]?\d*)', price_str)
    if match:
        try:
            return float(match.group(1).replace(',', ''))
        except:
            pass
    return np.nan

def is_installment_advanced(price_str, page_text, fuel_type=None, price_num=None):
    if not isinstance(price_str, str):
        return False

    # Explicit installment keywords
    installment_keywords = ['Ù‚Ø³Ø·', 'Ø´Ù‡Ø±ÙŠ', 'ØªÙ‚Ø³ÙŠØ·', 'installment', 'monthly', 'Ø¯ÙØ¹Ø© Ø£ÙˆÙ„Ù‰', 'Ø¯ÙØ¹Ø©']
    combined = price_str + " " + page_text
    for kw in installment_keywords:
        if re.search(rf'\b{kw}\b', combined, re.I):
            return True

    # Price rules based on fuel type
    if fuel_type is not None and price_num is not None:
        if fuel_type == 'ÙƒÙ‡Ø±Ø¨Ø§Ø¡' and price_num < 9000:
            return True
        if fuel_type == 'Ù‡Ø§ÙŠØ¨Ø±Ø¯' and price_num < 6000:
            return True

    return False

def extract_price_from_page(driver):
    json_data = extract_json_ld(driver.page_source)
    page_text = driver.find_element(By.TAG_NAME, "body").text
    price_text = "N/A"
    price_num = np.nan

    # 1. JSON-LD
    if json_data and 'offers' in json_data:
        offers = json_data['offers']
        if isinstance(offers, dict) and 'price' in offers:
            price_val = offers['price']
            try:
                if isinstance(price_val, (int, float)):
                    num = price_val
                else:
                    num = float(str(price_val).replace(',', ''))
                if 1000 <= num <= 200000:
                    currency = offers.get('priceCurrency', 'Ø¯ÙŠÙ†Ø§Ø±')
                    price_text = f"{price_val} {currency}"
                    price_num = num
            except:
                pass

    # 2. Visible price elements
    if price_num is np.nan:
        selectors = [
            "div.priceColor.bold.alignSelfCenter.font-18.ms-auto",
            "span.postCard__price",
            "div._price",
            "span.price"
        ]
        for selector in selectors:
            try:
                elem = driver.find_element(By.CSS_SELECTOR, selector)
                text = elem.text.strip()
                match = re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?|\d+)\s*(Ø¯ÙŠÙ†Ø§Ø±|JD)?', text)
                if match:
                    num_str = match.group(1)
                    try:
                        num = float(num_str.replace(',', ''))
                        if 1000 <= num <= 200000:
                            price_text = text
                            price_num = num
                            break
                    except:
                        pass
            except:
                continue

    # 3. General page search
    if price_num is np.nan:
        patterns = [
            r'(\d{1,3}(?:,\d{3})*)\s*(Ø¯ÙŠÙ†Ø§Ø±|JD)',
            r'(\d+)\s*(Ø¯ÙŠÙ†Ø§Ø±|JD)'
        ]
        for pattern in patterns:
            matches = re.findall(pattern, page_text)
            for num_str, unit in matches:
                clean_num = float(num_str.replace(',', ''))
                if 1000 <= clean_num <= 200000:
                    price_text = f"{num_str} Ø¯ÙŠÙ†Ø§Ø±"
                    price_num = clean_num
                    break
            if price_num is not np.nan:
                break

    return price_text, price_num

# -------------------- Other helper functions --------------------
def extract_transmission_from_page(driver):
    try:
        page_text = driver.find_element(By.TAG_NAME, "body").text
        if re.search(r'(Ø§ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ|automatic|Ø§ØªÙˆÙ…Ø§ØªÙŠÙƒ)', page_text, re.I):
            return "Ø§ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ"
        elif re.search(r'(ÙŠØ¯ÙˆÙŠ|manual|Ø¹Ø§Ø¯ÙŠ)', page_text, re.I):
            return "ÙŠØ¯ÙˆÙŠ"
    except:
        pass
    try:
        trans_elem = driver.find_element(By.XPATH, "//span[contains(text(),'Ù†Ø§Ù‚Ù„ Ø§Ù„Ø­Ø±ÙƒØ©')]/following-sibling::a")
        return trans_elem.text.strip()
    except:
        pass
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_color_from_page(driver):
    try:
        color_elem = driver.find_element(By.XPATH, "//span[contains(text(),'Ø§Ù„Ù„ÙˆÙ†')]/following-sibling::a")
        return color_elem.text.strip()
    except:
        try:
            page_text = driver.find_element(By.TAG_NAME, "body").text
            colors = ['Ø£Ø¨ÙŠØ¶', 'Ø£Ø³ÙˆØ¯', 'Ø±Ù…Ø§Ø¯ÙŠ', 'ÙØ¶ÙŠ', 'Ø£Ø²Ø±Ù‚', 'Ø£Ø­Ù…Ø±', 'Ø£Ø®Ø¶Ø±', 'Ø¨Ù†ÙŠ', 'Ø¨ÙŠØ¬', 'Ø°Ù‡Ø¨ÙŠ', 'Ø£Ø²Ø±Ù‚ ÙØ§ØªØ­']
            for c in colors:
                if c in page_text:
                    return c
        except:
            pass
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_insurance_from_page(driver):
    try:
        page_text = driver.find_element(By.TAG_NAME, "body").text
        if re.search(r'ØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„', page_text, re.I):
            return "ØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„"
        elif re.search(r'ØªØ£Ù…ÙŠÙ† Ø¥Ù„Ø²Ø§Ù…ÙŠ', page_text, re.I):
            return "ØªØ£Ù…ÙŠÙ† Ø¥Ù„Ø²Ø§Ù…ÙŠ"
        elif re.search(r'(ØªØ£Ù…ÙŠÙ†|Ù…Ø¤Ù…Ù†Ø©|Ù…Ø±Ø®ØµØ©)', page_text, re.I):
            return "ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†"
    except:
        pass
    return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†"

# -------------------- Browser setup --------------------
def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    return driver

# -------------------- Main program --------------------
def main():
    driver = setup_driver()
    base_url = "https://jo.opensooq.com"
    search_url = urljoin(base_url, "/ar/Ø³ÙŠØ§Ø±Ø§Øª-ÙˆÙ…Ø±ÙƒØ¨Ø§Øª/Ø³ÙŠØ§Ø±Ø§Øª-Ù„Ù„Ø¨ÙŠØ¹?search=true&Post_type=7511&Payment_Method=7513&CarCustoms=12565&has_price=1")

    print(fix_arabic("ğŸ”— Loading search page..."))
    driver.get(search_url)
    wait = WebDriverWait(driver, 20)

    # Initial statistics
    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a.postListItemData")))
        first_page_count = len(driver.find_elements(By.CSS_SELECTOR, "a.postListItemData"))
        try:
            last_page_link = driver.find_element(By.CSS_SELECTOR, "a[data-id='lastPageArrow']")
            last_page_href = last_page_link.get_attribute("href")
            match = re.search(r'page=(\d+)', last_page_href)
            total_pages = int(match.group(1)) if match else 1
        except:
            total_pages = 1
        total_ads_estimate = first_page_count * total_pages
        print(fix_arabic(f"\nğŸ“Š Search statistics:"))
        print(fix_arabic(f"   - Ads on first page: {first_page_count}"))
        print(fix_arabic(f"   - Available pages: {total_pages}"))
        print(fix_arabic(f"   - Estimated total: ~{total_ads_estimate} ads"))
    except Exception as e:
        print(fix_arabic(f"âš ï¸ Could not calculate statistics: {e}"))

    # Choose number of ads
    print(fix_arabic("\nğŸ”¢ How many ads do you want to scrape? (Enter a number or 'all' to scrape all): "))
    user_input = input().strip().lower()
    if user_input == 'all':
        max_ads = float('inf')
    else:
        try:
            max_ads = int(user_input)
        except:
            print(fix_arabic("âŒ Invalid input, scraping only 10 ads."))
            max_ads = 10

    all_ads = []
    ad_counter = 1
    current_page = 1
    stop_flag = False

    while not stop_flag:
        print(fix_arabic(f"\nğŸ“„ Scraping page {current_page}..."))
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a.postListItemData")))
            time.sleep(2)
            ad_cards = driver.find_elements(By.CSS_SELECTOR, "a.postListItemData")
            print(fix_arabic(f"   Found {len(ad_cards)} ads on this page."))

            for card in ad_cards:
                if ad_counter > max_ads:
                    stop_flag = True
                    break

                try:
                    relative_link = card.get_attribute("href")
                    if not relative_link:
                        continue
                    full_link = urljoin(base_url, relative_link)

                    # Data from card
                    card_text = card.text
                    try:
                        location_elem = card.find_element(By.CSS_SELECTOR, "div.flex.alignItems.gap-5.darkGrayColor")
                        location = location_elem.text.strip()
                    except:
                        location = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

                    year = extract_year(card_text)
                    mileage = extract_mileage(card_text)
                    condition = extract_condition(card_text)
                    seller_type = extract_seller_type(card)

                    # Initial model extraction
                    model = extract_model_from_card_and_page(card)

                    # Enter details page
                    price_text = "N/A"
                    price_num = np.nan
                    fuel_type = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                    insurance = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†"
                    transmission = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                    color = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

                    if full_link:
                        try:
                            driver.execute_script("window.open(arguments[0]);", full_link)
                            driver.switch_to.window(driver.window_handles[1])
                            time.sleep(2)

                            page_html = driver.page_source
                            model = extract_model_from_card_and_page(card, page_html, driver)

                            if year == "N/A":
                                year = extract_year(driver.find_element(By.TAG_NAME, "body").text)

                            # Extract price
                            price_text, price_num = extract_price_from_page(driver)

                            # Extract fuel type
                            fuel_type = extract_fuel_type_advanced(driver)

                            # Advanced installment check
                            page_text_full = driver.find_element(By.TAG_NAME, "body").text
                            if is_installment_advanced(price_text, page_text_full, fuel_type, price_num):
                                print(fix_arabic(f"â­ï¸ Skipping ad {ad_counter} (installment) - {fuel_type} at {price_num}"))
                                driver.close()
                                driver.switch_to.window(driver.window_handles[0])
                                continue

                            # Remaining data
                            insurance = extract_insurance_from_page(driver)
                            transmission = extract_transmission_from_page(driver)
                            color = extract_color_from_page(driver)

                            driver.close()
                            driver.switch_to.window(driver.window_handles[0])
                        except Exception as e:
                            print(fix_arabic(f"âš ï¸ Error opening details for ad {ad_counter}: {e}"))
                            if len(driver.window_handles) > 1:
                                driver.close()
                            driver.switch_to.window(driver.window_handles[0])
                            continue

                    if model == "ØºÙŠØ± Ù…ØªÙˆÙØ±" or not model:
                        model = extract_brand_model_from_text(card_text)

                    all_ads.append({
                        'ID': ad_counter,
                        'Model': model,
                        'Year': year,
                        'Condition': condition,
                        'Fuel Type': fuel_type,
                        'Mileage': mileage,
                        'Seller Type': seller_type,
                        'Location': location,
                        'Price': price_text,
                        'Insurance': insurance,
                        'Transmission': transmission,
                        'Color': color
                    })

                    print(fix_arabic(f"   âœ… {ad_counter}: {model[:50]}... | {price_text} | {fuel_type}"))
                    ad_counter += 1

                except Exception as e:
                    print(fix_arabic(f"âš ï¸ Error processing ad: {e}"))
                    if len(driver.window_handles) > 1:
                        driver.close()
                        driver.switch_to.window(driver.window_handles[0])
                    continue

            if stop_flag:
                break

            # Go to next page
            try:
                next_button = driver.find_element(By.CSS_SELECTOR, "a[data-id='nextPageArrow']")
                driver.execute_script("arguments[0].click();", next_button)
                time.sleep(3)
                current_page += 1
            except NoSuchElementException:
                print(fix_arabic("No more pages."))
                break

        except TimeoutException:
            print(fix_arabic("Page load timeout."))
            break
        except Exception as e:
            print(fix_arabic(f"Unexpected error: {e}"))
            break

    driver.quit()

    # Process and save data
    if all_ads:
        df = pd.DataFrame(all_ads)
        df = df[['ID', 'Model', 'Year', 'Condition', 'Fuel Type', 'Mileage', 'Seller Type', 'Location', 'Price', 'Insurance', 'Transmission', 'Color']]

        # Save Arabic version
        arabic_file = "cars_arabic.xlsx"
        df.to_excel(arabic_file, index=False)
        print(fix_arabic(f"\nâœ… Saved Arabic version: {arabic_file}"))

        # Create English version with smart translation
        print(fix_arabic("ğŸ”„ Translating data to English..."))
        df_en = df.copy()

        # Translate textual fields (except Model)
        for col in ['Condition', 'Fuel Type', 'Seller Type', 'Location', 'Insurance', 'Transmission', 'Color']:
            df_en[col] = df_en[col].apply(lambda x: translate_text(x))

        # Translate model using smart translation
        df_en['Model'] = df_en['Model'].apply(lambda x: translate_car_model_smart(x))

        # Replace invalid values
        df_en = df_en.replace(['N/A', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'ØºÙŠØ± Ù…ØªÙˆÙØ±', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†'], np.nan)

        # No ad_id added
        # Save Kaggle file
        kaggle_file = "jordan_cars_kaggle.csv"
        df_en.to_csv(kaggle_file, index=False, encoding='utf-8-sig')
        print(fix_arabic(f"âœ… Saved Kaggle version: {kaggle_file}"))

        # Quick statistics
        print(fix_arabic("\nğŸ“Š Data statistics:"))
        print(f"Total ads: {len(df_en)}")
        print(f"Electric cars: {df_en[df_en['Fuel Type'] == 'Electric'].shape[0]}")
        print(f"Hybrid cars: {df_en[df_en['Fuel Type'] == 'Hybrid'].shape[0]}")
        print(f"Petrol cars: {df_en[df_en['Fuel Type'] == 'Petrol'].shape[0]}")
        print(f"Diesel cars: {df_en[df_en['Fuel Type'] == 'Diesel'].shape[0]}")

        # Show sample
        print(fix_arabic("\nğŸ“‹ Sample of final data (first 5 rows):"))
        print(df_en[['Model', 'Year', 'Fuel Type', 'Price']].head())

    else:
        print(fix_arabic("No data found."))

if __name__ == "__main__":
    main()
