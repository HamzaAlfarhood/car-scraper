import time
import re
import json
import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
import arabic_reshaper
from bidi.algorithm import get_display
from urllib.parse import urljoin, quote
from deep_translator import GoogleTranslator

# -------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© --------------------
TRANSLATION_DICT = {
    # Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙˆÙ‚ÙˆØ¯
    'ÙƒÙ‡Ø±Ø¨Ø§Ø¡': 'Electric',
    'Ù‡Ø§ÙŠØ¨Ø±Ø¯': 'Hybrid',
    'Ø¨Ù†Ø²ÙŠÙ†': 'Petrol',
    'Ø¯ÙŠØ²Ù„': 'Diesel',
    # Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙŠØ§Ø±Ø©
    'Ø¬Ø¯ÙŠØ¯ (Ø²ÙŠØ±Ùˆ)': 'New (Zero)',
    'Ù…Ø³ØªØ¹Ù…Ù„': 'Used',
    # Ù†ÙˆØ¹ Ø§Ù„Ø¨Ø§Ø¦Ø¹
    'Ø´Ø®ØµÙŠ': 'Private',
    'Ù…Ø¹Ø±Ø¶': 'Dealer',
    'ÙˆÙƒØ§Ù„Ø©': 'Agency',
    'Ù…Ø¹Ø±Ø¶/ÙˆÙƒØ§Ù„Ø©': 'Dealer/Agency',
    # Ø§Ù„ØªØ£Ù…ÙŠÙ†
    'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†': 'No Insurance',
    'ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†': 'Insured',
    'ØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„': 'Comprehensive Insurance',
    'ØªØ£Ù…ÙŠÙ† Ø¥Ù„Ø²Ø§Ù…ÙŠ': 'Mandatory Insurance',
    'Ù…ÙƒÙÙˆÙ„Ø©': 'Warranty Included',
    # Ø§Ù„Ù…Ø¯Ù†
    'Ø¹Ù…Ø§Ù†': 'Amman',
    'Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡': 'Zarqa',
    'Ø¥Ø±Ø¨Ø¯': 'Irbid',
    'Ø§Ù„Ø¨Ù„Ù‚Ø§Ø¡': 'Balqa',
    'Ø§Ù„Ù…ÙØ±Ù‚': 'Mafraq',
    'Ø¬Ø±Ø´': 'Jerash',
    'Ù…Ø§Ø¯Ø¨Ø§': 'Madaba',
    'Ø§Ù„ÙƒØ±Ùƒ': 'Karak',
    'Ø§Ù„Ø·ÙÙŠÙ„Ø©': 'Tafila',
    'Ù…Ø¹Ø§Ù†': 'Ma\'an',
    'Ø§Ù„Ø¹Ù‚Ø¨Ø©': 'Aqaba',
    'Ø¹Ø¬Ù„ÙˆÙ†': 'Ajloun',
    'Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø­Ø±Ø©': 'Free Zone',
    # Ù†Ø§Ù‚Ù„ Ø§Ù„Ø­Ø±ÙƒØ©
    'Ø§ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ': 'Automatic',
    'ÙŠØ¯ÙˆÙŠ': 'Manual',
    'Ø§ØªÙˆÙ…Ø§ØªÙŠÙƒ': 'Automatic',
    # Ø§Ù„Ø£Ù„ÙˆØ§Ù†
    'Ø£Ø¨ÙŠØ¶': 'White',
    'Ø£Ø³ÙˆØ¯': 'Black',
    'Ø±Ù…Ø§Ø¯ÙŠ': 'Gray',
    'ÙØ¶ÙŠ': 'Silver',
    'Ø£Ø²Ø±Ù‚': 'Blue',
    'Ø£Ø­Ù…Ø±': 'Red',
    'Ø£Ø®Ø¶Ø±': 'Green',
    'Ø¨Ù†ÙŠ': 'Brown',
    'Ø¨ÙŠØ¬': 'Beige',
    'Ø°Ù‡Ø¨ÙŠ': 'Gold',
    'Ø£Ø²Ø±Ù‚ ÙØ§ØªØ­': 'Light Blue',
    # Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    'ØºÙŠØ± Ù…Ø­Ø¯Ø¯': 'Not Specified',
    'ØºÙŠØ± Ù…ØªÙˆÙØ±': 'N/A',
    'Ù†Ø¹Ù…': 'Yes',
    'Ù„Ø§': 'No',
}

# -------------------- Ù‚Ø§Ù…ÙˆØ³ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø§Ø±ÙƒØ§Øª ÙˆØ§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª --------------------
BRAND_TRANSLATION = {
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©
    'ØªÙˆÙŠÙˆØªØ§': 'Toyota',
    'Ù‡ÙˆÙ†Ø¯Ø§': 'Honda',
    'Ù†ÙŠØ³Ø§Ù†': 'Nissan',
    'Ù…ÙŠØªØ³ÙˆØ¨ÙŠØ´ÙŠ': 'Mitsubishi',
    'Ù…Ø§Ø²Ø¯Ø§': 'Mazda',
    'ÙƒÙŠØ§': 'Kia',
    'Ù‡ÙŠÙˆÙ†Ø¯Ø§ÙŠ': 'Hyundai',
    'Ø³ÙˆØ¨Ø§Ø±Ùˆ': 'Subaru',
    'Ø³ÙˆØ²ÙˆÙƒÙŠ': 'Suzuki',
    'Ø¯ÙŠÙ‡Ø§ØªØ³Ùˆ': 'Daihatsu',
    'Ø§ÙŠØ³ÙˆØ²Ùˆ': 'Isuzu',
    'Ù„ÙƒØ²Ø³': 'Lexus',
    'Ø§Ù†ÙÙŠÙ†ÙŠØªÙŠ': 'Infiniti',
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©
    'Ù…Ø±Ø³ÙŠØ¯Ø³': 'Mercedes-Benz',
    'Ø¨ÙŠ Ø§Ù… Ø¯Ø¨Ù„ÙŠÙˆ': 'BMW',
    'Ø£ÙˆØ¯ÙŠ': 'Audi',
    'ÙÙˆÙ„ÙƒØ³ ÙØ§Ø¬Ù†': 'Volkswagen',
    'Ø¨ÙˆØ±Ø´': 'Porsche',
    'Ø£ÙˆØ¨Ù„': 'Opel',
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©
    'ÙÙˆØ±Ø¯': 'Ford',
    'Ø´ÙŠÙØ±ÙˆÙ„ÙŠÙ‡': 'Chevrolet',
    'Ø¬ÙŠØ¨': 'Jeep',
    'ÙƒØ§Ø¯ÙŠÙ„Ø§Ùƒ': 'Cadillac',
    'ÙƒØ±Ø§ÙŠØ³Ù„Ø±': 'Chrysler',
    'Ø¯ÙˆØ¯Ø¬': 'Dodge',
    'Ø±Ø§Ù…': 'Ram',
    'Ø¬Ù…Ø³': 'GMC',
    'Ù„ÙŠÙ†ÙƒÙˆÙ„Ù†': 'Lincoln',
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ©
    'Ø±Ù†Ø¬ Ø±ÙˆÙØ±': 'Range Rover',
    'Ù„Ø§Ù†Ø¯ Ø±ÙˆÙØ±': 'Land Rover',
    'Ø¬Ø§ØºÙˆØ§Ø±': 'Jaguar',
    'Ù…ÙŠÙ†ÙŠ': 'Mini',
    'Ø¨Ù†ØªÙ„ÙŠ': 'Bentley',
    'Ø±ÙˆÙ„Ø² Ø±ÙˆÙŠØ³': 'Rolls-Royce',
    'Ø§Ø³ØªÙˆÙ† Ù…Ø§Ø±ØªÙ†': 'Aston Martin',
    'Ù…Ø§ÙƒÙ„Ø§Ø±ÙŠÙ†': 'McLaren',
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ø¥ÙŠØ·Ø§Ù„ÙŠØ©
    'ÙÙŠØ§Øª': 'Fiat',
    'Ø£Ù„ÙØ§ Ø±ÙˆÙ…ÙŠÙˆ': 'Alfa Romeo',
    'Ù…Ø§Ø²ÙŠØ±Ø§ØªÙŠ': 'Maserati',
    'Ù„ÙˆØªØ³': 'Lotus',
    'Ù„Ø§Ù…Ø¨ÙˆØ±ØºÙŠÙ†ÙŠ': 'Lamborghini',
    'ÙÙŠØ±Ø§Ø±ÙŠ': 'Ferrari',
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©
    'Ø±ÙŠÙ†Ùˆ': 'Renault',
    'Ø¨ÙŠØ¬Ùˆ': 'Peugeot',
    'Ø³ÙŠØªØ±ÙˆÙŠÙ†': 'CitroÃ«n',
    'Ø¯Ø§Ø³ÙŠØ§': 'Dacia',
    # Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„ØµÙŠÙ†ÙŠØ©
    'Ø¨ÙŠ ÙˆØ§ÙŠ Ø¯ÙŠ': 'BYD',
    'Ø§Ù… Ø¬ÙŠ': 'MG',
    'Ø¬Ø§Ùƒ': 'JAC',
    'Ù‡Ø§ÙØ§Ù„': 'Haval',
    'Ø´Ø§Ù†Ø¬Ø§Ù†': 'Changan',
    'Ø¬ÙŠÙ„ÙŠ': 'Geely',
    'Ø´ÙŠØ±ÙŠ': 'Chery',
    'Ù†ÙŠØªØ§': 'Neta',
    'Ø¨Ø±ÙˆØªÙˆÙ†': 'Proton',
    # Ù…Ø§Ø±ÙƒØ§Øª Ø£Ø®Ø±Ù‰
    'ØªÙŠØ³Ù„Ø§': 'Tesla',
    'ÙÙˆÙ„ÙÙˆ': 'Volvo',
}

MODEL_TRANSLATION = {
    # ØªÙˆÙŠÙˆØªØ§
    'ÙƒØ§Ù…Ø±ÙŠ': 'Camry',
    'ÙƒÙˆØ±ÙˆÙ„Ø§': 'Corolla',
    'ÙŠØ§Ø±Ø³': 'Yaris',
    'Ø±Ø§Ù ÙÙˆØ±': 'RAV4',
    'Ù‡ÙŠÙ„ÙˆÙƒØ³': 'Hilux',
    'Ù„Ø§Ù†Ø¯ ÙƒØ±ÙˆØ²Ø±': 'Land Cruiser',
    'Ø¨Ø±Ø§Ø¯Ùˆ': 'Prado',
    'Ø§ÙØ§Ù„ÙˆÙ†': 'Avalon',
    'Ø³ÙˆØ¨Ø±Ø§': 'Supra',
    # Ù‡ÙˆÙ†Ø¯Ø§
    'Ø³ÙŠÙÙŠÙƒ': 'Civic',
    'Ø§ÙƒÙˆØ±Ø¯': 'Accord',
    'Ø³ÙŠ Ø§Ø± ÙÙŠ': 'CR-V',
    'Ø§ØªØ´ Ø§Ø± ÙÙŠ': 'HR-V',
    'Ø¨Ø§ÙŠÙ„ÙˆØª': 'Pilot',
    # Ù†ÙŠØ³Ø§Ù†
    'Ø³Ù†ØªØ±Ø§': 'Sentra',
    'Ø§Ù„ØªÙŠÙ…Ø§': 'Altima',
    'Ù…Ø§ÙƒØ³ÙŠÙ…Ø§': 'Maxima',
    'Ø¨Ø§ØªØ±ÙˆÙ„': 'Patrol',
    'Ù‚Ø´Ù‚Ø§ÙŠ': 'Qashqai',
    # Ù‡ÙŠÙˆÙ†Ø¯Ø§ÙŠ
    'Ø³ÙˆÙ†Ø§ØªØ§': 'Sonata',
    'Ø§Ù„Ù†ØªØ±Ø§': 'Elantra',
    'Ø§ÙØ§Ù†ØªÙŠ': 'Elantra',
    'Ø§ÙƒØ³Ù†Øª': 'Accent',
    'ØªÙˆØ³Ø§Ù†': 'Tucson',
    'Ø³Ø§Ù†ØªØ§ÙÙŠ': 'Santa Fe',
    'Ø§Ø²ÙŠØ±Ø§': 'Azera',
    # ÙƒÙŠØ§
    'Ø³Ø¨ÙˆØ±ØªØ§Ø¬': 'Sportage',
    'Ø³ÙˆØ±ÙŠÙ†ØªÙˆ': 'Sorento',
    'Ø§ÙˆØ¨ØªÙŠÙ…Ø§': 'Optima',
    'ÙƒØ§Ø¯ÙŠÙ†Ø²Ø§': 'Cadenza',
    'Ø±ÙŠÙˆ': 'Rio',
    'Ø³ÙˆÙ„': 'Soul',
    # Ù…Ø±Ø³ÙŠØ¯Ø³
    'Ø§Ù„ÙØ¦Ø©-Ø³ÙŠ': 'C-Class',
    'Ø§Ù„ÙØ¦Ø©-Ø§ÙŠ': 'E-Class',
    'Ø§Ù„ÙØ¦Ø©-Ø§Ø³': 'S-Class',
    'Ø¬ÙŠ Ø§Ù„ Ø§ÙŠ': 'GLE',
    'Ø¬ÙŠ Ø§Ù„ Ø³ÙŠ': 'GLC',
    'Ø§ÙŠÙ‡ Ø§Ù… Ø¬ÙŠ': 'AMG',
    # Ø¨ÙŠ Ø§Ù… Ø¯Ø¨Ù„ÙŠÙˆ
    'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©': '3 Series',
    'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø®Ø§Ù…Ø³Ø©': '5 Series',
    'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø³Ø§Ø¨Ø¹Ø©': '7 Series',
    'Ø§ÙƒØ³ 1': 'X1',
    'Ø§ÙƒØ³ 3': 'X3',
    'Ø§ÙƒØ³ 5': 'X5',
    # Ø£ÙˆØ¯ÙŠ
    'Ø§ÙŠÙ‡ 3': 'A3',
    'Ø§ÙŠÙ‡ 4': 'A4',
    'Ø§ÙŠÙ‡ 6': 'A6',
    'Ø§ÙŠÙ‡ 8': 'A8',
    'ÙƒÙŠÙˆ 2': 'Q2',
    'ÙƒÙŠÙˆ 3': 'Q3',
    'ÙƒÙŠÙˆ 5': 'Q5',
    'ÙƒÙŠÙˆ 7': 'Q7',
    # ÙÙˆØ±Ø¯
    'ÙÙˆÙƒØ³': 'Focus',
    'ÙÙŠÙˆØ¬Ù†': 'Fusion',
    'Ù…ÙˆØ³ØªØ§Ù†Ø¬': 'Mustang',
    'Ø§Ù-150': 'F-150',
    'Ø§ÙƒØ³Ø¨Ù„ÙˆØ±Ø±': 'Explorer',
    # Ø´ÙŠÙØ±ÙˆÙ„ÙŠÙ‡
    'Ù…Ø§Ù„ÙŠØ¨Ùˆ': 'Malibu',
    'ÙƒØ§Ù…Ø§Ø±Ùˆ': 'Camaro',
    'ÙƒÙˆØ±ÙÙŠØª': 'Corvette',
    'Ø³ÙŠÙ„ÙØ±Ø§Ø¯Ùˆ': 'Silverado',
    'ØªØ§Ù‡Ùˆ': 'Tahoe',
    # ØªÙŠØ³Ù„Ø§
    'Ù…ÙˆØ¯ÙŠÙ„ 3': 'Model 3',
    'Ù…ÙˆØ¯ÙŠÙ„ Ø§Ø³': 'Model S',
    'Ù…ÙˆØ¯ÙŠÙ„ Ø§ÙƒØ³': 'Model X',
    'Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§ÙŠ': 'Model Y',
    # Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø´Ø§Ø¦Ø¹Ø© Ø£Ø®Ø±Ù‰
    'Ø¨Ø§Ù†Ø§Ù…ÙŠØ±Ø§': 'Panamera',
    'ÙƒØ§ÙŠÙŠÙ†': 'Cayenne',
    'Ù…Ø§ÙƒØ§Ù†': 'Macan',
    'Ø¬ÙˆÙ„Ù': 'Golf',
    'Ø¨Ø§Ø³Ø§Øª': 'Passat',
    'Ù„ÙˆØ¬Ø§Ù†': 'Logan',
    'Ø¯Ø§Ø³ØªØ±': 'Duster',
    'Ø³Ø§Ù†Ø¯ÙŠØ±Ùˆ': 'Sandero',
}

# ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ¦Ø© (Trim)
TRIM_KEYWORDS = {
    'Standard': ['standard', 'base', 'Ø§Ø³Ø§Ø³ÙŠ', 'Ù‚ÙŠØ§Ø³ÙŠ'],
    'Sport': ['sport', 'spt', 'Ø±ÙŠØ§Ø¶ÙŠ'],
    'Luxury': ['luxury', 'lux', 'ÙØ§Ø®Ø±'],
    'Premium': ['premium', 'Ø¨Ø±ÙŠÙ…ÙŠÙˆÙ…'],
    'Limited': ['limited', 'Ù„ÙŠÙ…ØªØ¯', 'Ù…Ø­Ø¯ÙˆØ¯'],
    'Platinum': ['platinum', 'Ø¨Ù„Ø§ØªÙŠÙ†ÙŠÙˆÙ…'],
    'Titanium': ['titanium', 'ØªÙŠØªØ§Ù†ÙŠÙˆÙ…'],
    'SEL': ['sel'],
    'SE': ['se'],
    'LE': ['le'],
    'XLE': ['xle'],
    'XE': ['xe'],
    'GT': ['gt'],
    'GTE': ['gte'],
    'Plus': ['plus', 'Ø¨Ù„Ø³'],
    'Pro': ['pro', 'Ø¨Ø±Ùˆ'],
}

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
CAR_BRANDS = list(BRAND_TRANSLATION.keys())

# -------------------- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ --------------------
def search_car_model_online(car_name):
    """
    Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ±Ø¬Ù…Ø© Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª (ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§)
    """
    try:
        search_query = quote(f"{car_name} car")
        url = f"https://en.wikipedia.org/wiki/{search_query.replace(' ', '_')}"
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=5)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            title = soup.find('h1', {'id': 'firstHeading'})
            if title:
                return title.text.strip()
    except:
        pass
    return None

def split_car_model(text):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡: Ù…Ø§Ø±ÙƒØ©ØŒ Ù…ÙˆØ¯ÙŠÙ„ØŒ ÙØ¦Ø©
    """
    text = text.strip()
    brand = None
    model = None
    trim = []
    remaining = []

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø§Ø±ÙƒØ©
    for ar_brand in BRAND_TRANSLATION.keys():
        if ar_brand in text:
            brand = ar_brand
            text = text.replace(ar_brand, '', 1).strip()
            break

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    words = text.split()
    for word in words:
        found = False
        for ar_model in MODEL_TRANSLATION.keys():
            if ar_model in word or word in ar_model:
                model = ar_model
                text = text.replace(ar_model, '', 1).strip()
                found = True
                break
        if found:
            break

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙØ¦Ø© (Trim)
    words = text.split()
    for word in words:
        word_lower = word.lower()
        matched = False
        for trim_name, keywords in TRIM_KEYWORDS.items():
            if word_lower in keywords or any(kw in word_lower for kw in keywords):
                trim.append(trim_name)
                text = text.replace(word, '', 1).strip()
                matched = True
                break
        if not matched:
            remaining.append(word)

    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
    extra = ' '.join(remaining).strip()
    if extra and not model:
        model = extra
        extra = ''

    return {
        'brand': brand,
        'model': model,
        'trim': ' '.join(trim) if trim else None,
        'extra': extra if extra else None
    }

def translate_car_model_smart(text):
    """
    ØªØ±Ø¬Ù…Ø© Ø°ÙƒÙŠØ© Ù„Ø§Ø³Ù… Ø§Ù„Ø³ÙŠØ§Ø±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ ÙˆØ§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª.
    """
    if not isinstance(text, str) or text.strip() == '':
        return text
    original = text.strip()

    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³Ù…
    parts = split_car_model(original)

    translated_parts = []

    # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…Ø§Ø±ÙƒØ©
    if parts['brand']:
        translated_parts.append(BRAND_TRANSLATION.get(parts['brand'], parts['brand']))

    # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    if parts['model']:
        if parts['model'] in MODEL_TRANSLATION:
            translated_parts.append(MODEL_TRANSLATION[parts['model']])
        else:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
            online = search_car_model_online(parts['model'])
            if online:
                translated_parts.append(online)
            else:
                translated_parts.append(parts['model'])  # Ù†ØªØ±ÙƒÙ‡ ÙƒÙ…Ø§ Ù‡Ùˆ

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ÙØ¦Ø©
    if parts['trim']:
        translated_parts.append(parts['trim'])

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
    if parts['extra']:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø±Ø¨ÙŠ Ù†ØªØ±Ø¬Ù…Ù‡ Ø¹Ø§Ø¯ÙŠØ§Ù‹
        if any('\u0600' <= c <= '\u06FF' for c in parts['extra']):
            translated_parts.append(translate_text_fallback(parts['extra']))
        else:
            translated_parts.append(parts['extra'])

    # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø³ØªØ·Ø¹ ØªØ±Ø¬Ù…Ø© Ø£ÙŠ Ø´ÙŠØ¡ØŒ Ù†Ø¹ÙŠØ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
    if not translated_parts:
        return original

    return ' '.join(translated_parts)

def translate_text_fallback(text, target='en'):
    """ØªØ±Ø¬Ù…Ø© Ù†Øµ Ø¹Ø§Ø¯ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø£Ùˆ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¢Ù„ÙŠØ©"""
    if text in TRANSLATION_DICT:
        return TRANSLATION_DICT[text]
    try:
        translated = GoogleTranslator(source='ar', target=target).translate(text)
        if translated and translated != text:
            return translated
    except:
        pass
    return text

def translate_text(text, target='en'):
    # Ø¯Ø§Ù„Ø© Ø¹Ø§Ù…Ø© ØªØ³ØªØ®Ø¯Ù… Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£Ø®Ø±Ù‰ (ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„)
    return translate_text_fallback(text, target)

def fix_arabic(text):
    """Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„ØµØ­ÙŠØ­"""
    if isinstance(text, str) and any("\u0600" <= c <= "\u06FF" for c in text):
        try:
            reshaped_text = arabic_reshaper.reshape(text)
            return get_display(reshaped_text)
        except:
            return text
    return text

# -------------------- Ø¯ÙˆØ§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© --------------------
def convert_arabic_numbers(text):
    arabic_nums = str.maketrans('Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©', '0123456789')
    return text.translate(arabic_nums)

def extract_year(text):
    text = convert_arabic_numbers(text)
    matches = re.findall(r'\b(19[0-9]{2}|20[0-9]{2})\b', text)
    for match in matches:
        year = int(match)
        if 1900 <= year <= 2025:
            return match
    return "N/A"

def extract_mileage(text):
    text = convert_arabic_numbers(text)
    patterns = [
        r'(\d+[,.]?\d*\s*-\s*\d+[,.]?\d*)\s*(ÙƒÙ…|ÙƒÙŠÙ„ÙˆÙ…ØªØ±|km)',
        r'(\+?\d+[,.]?\d*)\s*(ÙƒÙ…|ÙƒÙŠÙ„ÙˆÙ…ØªØ±|km)'
    ]
    for pattern in patterns:
        match = re.search(pattern, text, re.I)
        if match:
            return match.group(0)
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_condition(text):
    if re.search(r'(Ø¬Ø¯ÙŠØ¯|Ø²ÙŠØ±Ùˆ|zero|ÙˆÙƒØ§Ù„Ø©|new)', text, re.I):
        return "Ø¬Ø¯ÙŠØ¯ (Ø²ÙŠØ±Ùˆ)"
    elif re.search(r'(Ù…Ø³ØªØ¹Ù…Ù„|used)', text, re.I):
        return "Ù…Ø³ØªØ¹Ù…Ù„"
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_seller_type(card):
    try:
        badge = card.find_element(By.CSS_SELECTOR, "div.memberBadge")
        badge_text = badge.text
        if "Ù…Ø³ØªØ®Ø¯Ù… Ù…ÙˆØ«Ù‚" in badge_text:
            return "Ø´Ø®ØµÙŠ"
        elif "Ù†Ø´Ø§Ø· ØªØ¬Ø§Ø±ÙŠ Ù…ÙˆØ«Ù‚" in badge_text:
            return "Ù…Ø¹Ø±Ø¶/ÙˆÙƒØ§Ù„Ø©"
    except:
        pass
    text = card.text
    if re.search(r'(Ù…Ø¹Ø±Ø¶|dealership)', text, re.I):
        return "Ù…Ø¹Ø±Ø¶"
    elif re.search(r'(ÙˆÙƒØ§Ù„Ø©|agency)', text, re.I):
        return "ÙˆÙƒØ§Ù„Ø©"
    elif re.search(r'(Ø´Ø®ØµÙŠ|private|Ù…Ø§Ù„Ùƒ)', text, re.I):
        return "Ø´Ø®ØµÙŠ"
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_json_ld(html):
    try:
        pattern = r'<script type="application/ld\+json">(.*?)</script>'
        scripts = re.findall(pattern, html, re.DOTALL)
        for script in scripts:
            try:
                data = json.loads(script)
                if isinstance(data, dict) and data.get('@type') == 'Vehicle':
                    return data
                elif isinstance(data, list):
                    for item in data:
                        if item.get('@type') == 'Vehicle':
                            return item
            except:
                continue
    except:
        pass
    return None

# -------------------- Ø¯ÙˆØ§Ù„ Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ --------------------
def extract_model_from_card_and_page(card, page_html=None, page_driver=None):
    # 1. JSON-LD
    if page_html:
        json_data = extract_json_ld(page_html)
        if json_data:
            if 'name' in json_data and json_data['name']:
                return json_data['name']
            if 'model' in json_data and json_data['model']:
                return json_data['model']
    # 2. h1 Ù…Ù† ØµÙØ­Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„
    if page_driver:
        try:
            h1 = page_driver.find_element(By.CSS_SELECTOR, "h1")
            h1_text = h1.text.strip()
            if h1_text:
                return h1_text
        except:
            pass
    # 3. h2 ÙÙŠ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©
    try:
        h2 = card.find_element(By.CSS_SELECTOR, "h2.breakWord.trimTwoLines.font-20, h2.breakWord, h2")
        h2_text = h2.text.strip()
        if h2_text:
            return h2_text
    except:
        pass
    # 4. Ø£ÙˆÙ„ Ø³Ø·Ø± Ù…Ù† Ù†Øµ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©
    card_text = card.text
    lines = [line.strip() for line in card_text.split('\n') if line.strip()]
    if lines:
        return lines[0]
    # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
    return extract_brand_model_from_text(card_text)

def extract_brand_model_from_text(text):
    text = text.strip()
    found_brand = None
    for brand in CAR_BRANDS:
        if brand in text:
            found_brand = brand
            break
    if found_brand:
        rest = text.replace(found_brand, '', 1).strip()
        rest = re.sub(r'\b(Ù„Ù„Ø¨ÙŠØ¹|Ø³ÙŠØ§Ø±Ø©|Ø¨Ø­Ø§Ù„Ø©|Ù†Ø¸ÙŠÙ|Ù…Ø³ØªØ¹Ù…Ù„|Ø¬Ø¯ÙŠØ¯|Ø²ÙŠØ±Ùˆ|ÙˆÙƒØ§Ù„Ø©|Ù…Ø¹Ø±Ø¶|Ø´Ø®ØµÙŠ|ÙØ­Øµ|ÙƒØ§Ù…Ù„|Ù…Ù…ØªØ§Ø²Ø©|Ø¹Ø¯Ø§Ø¯|Ù‚Ù„ÙŠÙ„|ÙÙ„|ÙƒØ§Ø´|Ø§Ù‚Ø³Ø§Ø·|Ø¨Ø¯ÙˆÙ†|Ø¬Ù…Ø±Ùƒ|Ù„Ù‚Ø·Ø©|Ù…Ø§Ù„Ùƒ|Ø´Ø±ÙƒÙ‡|Ø§Ù„ÙˆÙƒØ§Ù„Ù‡|Ù†Ø¸ÙŠÙØ©|Ø§Ø³ØªØ®Ø¯Ø§Ù…)\b', '', rest, flags=re.I)
        rest = re.sub(r'\s+', ' ', rest).strip()
        if rest:
            return f"{found_brand} {rest}"
        else:
            return found_brand
    cleaned = re.sub(r'\b(Ù„Ù„Ø¨ÙŠØ¹|Ø³ÙŠØ§Ø±Ø©|Ø¨Ø­Ø§Ù„Ø©|Ù†Ø¸ÙŠÙ|Ù…Ø³ØªØ¹Ù…Ù„|Ø¬Ø¯ÙŠØ¯|Ø²ÙŠØ±Ùˆ|ÙˆÙƒØ§Ù„Ø©|Ù…Ø¹Ø±Ø¶|Ø´Ø®ØµÙŠ|ÙØ­Øµ|ÙƒØ§Ù…Ù„|Ù…Ù…ØªØ§Ø²Ø©|Ø¹Ø¯Ø§Ø¯|Ù‚Ù„ÙŠÙ„|ÙÙ„|ÙƒØ§Ø´|Ø§Ù‚Ø³Ø§Ø·|Ø¨Ø¯ÙˆÙ†|Ø¬Ù…Ø±Ùƒ|Ù„Ù‚Ø·Ø©|Ù…Ø§Ù„Ùƒ|Ø´Ø±ÙƒÙ‡)\b', '', text, flags=re.I)
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned if cleaned else "ØºÙŠØ± Ù…ØªÙˆÙØ±"

# -------------------- Ø¯ÙˆØ§Ù„ Ù…Ø­Ø³Ù†Ø© Ù„Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚ÙˆØ¯ --------------------
def extract_fuel_type_advanced(driver):
    json_data = extract_json_ld(driver.page_source)
    page_text = driver.find_element(By.TAG_NAME, "body").text.lower()
    if json_data and 'fuelType' in json_data:
        fuel = json_data['fuelType'].lower()
        if 'electric' in fuel:
            return "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"
        elif 'hybrid' in fuel:
            return "Ù‡Ø§ÙŠØ¨Ø±Ø¯"
        elif 'diesel' in fuel:
            return "Ø¯ÙŠØ²Ù„"
        elif 'petrol' in fuel or 'gasoline' in fuel:
            return "Ø¨Ù†Ø²ÙŠÙ†"
    try:
        fuel_elem = driver.find_element(By.XPATH, "//span[contains(text(),'Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚ÙˆØ¯')]/following-sibling::a")
        fuel_text = fuel_elem.text.strip()
        if fuel_text:
            if 'ÙƒÙ‡Ø±Ø¨Ø§Ø¡' in fuel_text:
                return "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"
            elif 'Ù‡Ø§ÙŠØ¨Ø±Ø¯' in fuel_text:
                return "Ù‡Ø§ÙŠØ¨Ø±Ø¯"
            elif 'Ø¯ÙŠØ²Ù„' in fuel_text:
                return "Ø¯ÙŠØ²Ù„"
            elif 'Ø¨Ù†Ø²ÙŠÙ†' in fuel_text:
                return "Ø¨Ù†Ø²ÙŠÙ†"
    except:
        pass
    if re.search(r'\b(Ù‡Ø§ÙŠØ¨Ø±Ø¯|hybrid)\b', page_text, re.I):
        return "Ù‡Ø§ÙŠØ¨Ø±Ø¯"
    if re.search(r'\b(Ø¯ÙŠØ²Ù„|diesel)\b', page_text, re.I):
        return "Ø¯ÙŠØ²Ù„"
    if re.search(r'\b(Ø¨Ù†Ø²ÙŠÙ†|petrol|gasoline)\b', page_text, re.I):
        return "Ø¨Ù†Ø²ÙŠÙ†"
    if re.search(r'\b(ÙƒÙ‡Ø±Ø¨Ø§Ø¡|electric|ev)\b', page_text, re.I):
        return "ÙƒÙ‡Ø±Ø¨Ø§Ø¡"
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

# -------------------- Ø¯ÙˆØ§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø± ÙˆÙƒØ´Ù Ø§Ù„ØªÙ‚Ø³ÙŠØ· Ø§Ù„Ù…ØªÙ‚Ø¯Ù… --------------------
def clean_price_number(price_str):
    if not isinstance(price_str, str) or price_str == "N/A":
        return np.nan
    match = re.search(r'(\d+[,.]?\d*)', price_str)
    if match:
        try:
            return float(match.group(1).replace(',', ''))
        except:
            pass
    return np.nan

def is_installment_advanced(price_str, page_text, fuel_type=None, price_num=None):
    if not isinstance(price_str, str):
        return False

    # ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ØµØ±ÙŠØ­Ø© Ù„Ù„ØªÙ‚Ø³ÙŠØ·
    installment_keywords = ['Ù‚Ø³Ø·', 'Ø´Ù‡Ø±ÙŠ', 'ØªÙ‚Ø³ÙŠØ·', 'installment', 'monthly', 'Ø¯ÙØ¹Ø© Ø£ÙˆÙ„Ù‰', 'Ø¯ÙØ¹Ø©']
    combined = price_str + " " + page_text
    for kw in installment_keywords:
        if re.search(rf'\b{kw}\b', combined, re.I):
            return True

    # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³Ø¹Ø± Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚ÙˆØ¯
    if fuel_type is not None and price_num is not None:
        if fuel_type == 'ÙƒÙ‡Ø±Ø¨Ø§Ø¡' and price_num < 9000:
            return True
        if fuel_type == 'Ù‡Ø§ÙŠØ¨Ø±Ø¯' and price_num < 6000:
            return True

    return False

def extract_price_from_page(driver):
    json_data = extract_json_ld(driver.page_source)
    page_text = driver.find_element(By.TAG_NAME, "body").text
    price_text = "N/A"
    price_num = np.nan

    # 1. JSON-LD
    if json_data and 'offers' in json_data:
        offers = json_data['offers']
        if isinstance(offers, dict) and 'price' in offers:
            price_val = offers['price']
            try:
                if isinstance(price_val, (int, float)):
                    num = price_val
                else:
                    num = float(str(price_val).replace(',', ''))
                if 1000 <= num <= 200000:
                    currency = offers.get('priceCurrency', 'Ø¯ÙŠÙ†Ø§Ø±')
                    price_text = f"{price_val} {currency}"
                    price_num = num
            except:
                pass

    # 2. Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø±Ø¦ÙŠØ©
    if price_num is np.nan:
        selectors = [
            "div.priceColor.bold.alignSelfCenter.font-18.ms-auto",
            "span.postCard__price",
            "div._price",
            "span.price"
        ]
        for selector in selectors:
            try:
                elem = driver.find_element(By.CSS_SELECTOR, selector)
                text = elem.text.strip()
                match = re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?|\d+)\s*(Ø¯ÙŠÙ†Ø§Ø±|JD)?', text)
                if match:
                    num_str = match.group(1)
                    try:
                        num = float(num_str.replace(',', ''))
                        if 1000 <= num <= 200000:
                            price_text = text
                            price_num = num
                            break
                    except:
                        pass
            except:
                continue

    # 3. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù… ÙÙŠ Ø§Ù„ØµÙØ­Ø©
    if price_num is np.nan:
        patterns = [
            r'(\d{1,3}(?:,\d{3})*)\s*(Ø¯ÙŠÙ†Ø§Ø±|JD)',
            r'(\d+)\s*(Ø¯ÙŠÙ†Ø§Ø±|JD)'
        ]
        for pattern in patterns:
            matches = re.findall(pattern, page_text)
            for num_str, unit in matches:
                clean_num = float(num_str.replace(',', ''))
                if 1000 <= clean_num <= 200000:
                    price_text = f"{num_str} Ø¯ÙŠÙ†Ø§Ø±"
                    price_num = clean_num
                    break
            if price_num is not np.nan:
                break

    return price_text, price_num

# -------------------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø£Ø®Ø±Ù‰ --------------------
def extract_transmission_from_page(driver):
    try:
        page_text = driver.find_element(By.TAG_NAME, "body").text
        if re.search(r'(Ø§ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ|automatic|Ø§ØªÙˆÙ…Ø§ØªÙŠÙƒ)', page_text, re.I):
            return "Ø§ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ"
        elif re.search(r'(ÙŠØ¯ÙˆÙŠ|manual|Ø¹Ø§Ø¯ÙŠ)', page_text, re.I):
            return "ÙŠØ¯ÙˆÙŠ"
    except:
        pass
    try:
        trans_elem = driver.find_element(By.XPATH, "//span[contains(text(),'Ù†Ø§Ù‚Ù„ Ø§Ù„Ø­Ø±ÙƒØ©')]/following-sibling::a")
        return trans_elem.text.strip()
    except:
        pass
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_color_from_page(driver):
    try:
        color_elem = driver.find_element(By.XPATH, "//span[contains(text(),'Ø§Ù„Ù„ÙˆÙ†')]/following-sibling::a")
        return color_elem.text.strip()
    except:
        try:
            page_text = driver.find_element(By.TAG_NAME, "body").text
            colors = ['Ø£Ø¨ÙŠØ¶', 'Ø£Ø³ÙˆØ¯', 'Ø±Ù…Ø§Ø¯ÙŠ', 'ÙØ¶ÙŠ', 'Ø£Ø²Ø±Ù‚', 'Ø£Ø­Ù…Ø±', 'Ø£Ø®Ø¶Ø±', 'Ø¨Ù†ÙŠ', 'Ø¨ÙŠØ¬', 'Ø°Ù‡Ø¨ÙŠ', 'Ø£Ø²Ø±Ù‚ ÙØ§ØªØ­']
            for c in colors:
                if c in page_text:
                    return c
        except:
            pass
    return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

def extract_insurance_from_page(driver):
    try:
        page_text = driver.find_element(By.TAG_NAME, "body").text
        if re.search(r'ØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„', page_text, re.I):
            return "ØªØ£Ù…ÙŠÙ† Ø´Ø§Ù…Ù„"
        elif re.search(r'ØªØ£Ù…ÙŠÙ† Ø¥Ù„Ø²Ø§Ù…ÙŠ', page_text, re.I):
            return "ØªØ£Ù…ÙŠÙ† Ø¥Ù„Ø²Ø§Ù…ÙŠ"
        elif re.search(r'(ØªØ£Ù…ÙŠÙ†|Ù…Ø¤Ù…Ù†Ø©|Ù…Ø±Ø®ØµØ©)', page_text, re.I):
            return "ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†"
    except:
        pass
    return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†"

# -------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­ (Ù…Ø¹Ø¯Ù„ Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ GitHub Actions) --------------------
def setup_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù‡Ù…Ø© Ù„Ù„Ø¹Ù…Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© headless (GitHub Actions)
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--remote-debugging-port=9222")

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… webdriver-manager Ù„ØªØ«Ø¨ÙŠØª chromedriver ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    return driver

# -------------------- Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Ù…Ø¹Ø¯Ù„ Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ) --------------------
def main():
    driver = setup_driver()
    base_url = "https://jo.opensooq.com"
    search_url = urljoin(base_url, "/ar/Ø³ÙŠØ§Ø±Ø§Øª-ÙˆÙ…Ø±ÙƒØ¨Ø§Øª/Ø³ÙŠØ§Ø±Ø§Øª-Ù„Ù„Ø¨ÙŠØ¹?search=true&Post_type=7511&Payment_Method=7513&CarCustoms=12565&has_price=1")

    print(fix_arabic("ğŸ”— Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ ØµÙØ­Ø© Ø§Ù„Ø¨Ø­Ø«..."))
    driver.get(search_url)
    wait = WebDriverWait(driver, 20)

    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…Ø¨Ø¯Ø¦ÙŠØ©
    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a.postListItemData")))
        first_page_count = len(driver.find_elements(By.CSS_SELECTOR, "a.postListItemData"))
        try:
            last_page_link = driver.find_element(By.CSS_SELECTOR, "a[data-id='lastPageArrow']")
            last_page_href = last_page_link.get_attribute("href")
            match = re.search(r'page=(\d+)', last_page_href)
            total_pages = int(match.group(1)) if match else 1
        except:
            total_pages = 1
        total_ads_estimate = first_page_count * total_pages
        print(fix_arabic(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø«:"))
        print(fix_arabic(f"   - Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: {first_page_count}"))
        print(fix_arabic(f"   - Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©: {total_pages}"))
        print(fix_arabic(f"   - Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: ~{total_ads_estimate} Ø¥Ø¹Ù„Ø§Ù†"))
    except Exception as e:
        print(fix_arabic(f"âš ï¸ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}"))

    # ğŸŸ¢ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ù‚ÙŠÙ…Ø© Ø«Ø§Ø¨ØªØ© (Ù…Ø«Ù„Ø§Ù‹ 100) Ø£Ùˆ 'all'
    # Ø­ØªÙ‰ ØªØ¹Ù…Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© ØºÙŠØ± ØªÙØ§Ø¹Ù„ÙŠØ© Ù…Ø«Ù„ GitHub Actions
    user_input = 'all'   # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ Ø±Ù‚Ù… Ù…Ø­Ø¯Ø¯ Ù…Ø«Ù„ '100' Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª

    if user_input == 'all':
        max_ads = float('inf')
    else:
        try:
            max_ads = int(user_input)
        except:
            print(fix_arabic("âŒ Ø¥Ø¯Ø®Ø§Ù„ ØºÙŠØ± ØµØ­ÙŠØ­ØŒ Ø³ÙŠØªÙ… Ø³Ø­Ø¨ 10 Ø¥Ø¹Ù„Ø§Ù†Ø§Øª ÙÙ‚Ø·."))
            max_ads = 10

    all_ads = []
    ad_counter = 1
    current_page = 1
    stop_flag = False

    while not stop_flag:
        print(fix_arabic(f"\nğŸ“„ Ø¬Ø§Ø±ÙŠ Ù…Ø³Ø­ Ø§Ù„ØµÙØ­Ø© {current_page}..."))
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a.postListItemData")))
            time.sleep(2)
            ad_cards = driver.find_elements(By.CSS_SELECTOR, "a.postListItemData")
            print(fix_arabic(f"   ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(ad_cards)} Ø¥Ø¹Ù„Ø§Ù† ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©."))

            for card in ad_cards:
                if ad_counter > max_ads:
                    stop_flag = True
                    break

                try:
                    relative_link = card.get_attribute("href")
                    if not relative_link:
                        continue
                    full_link = urljoin(base_url, relative_link)

                    # Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©
                    card_text = card.text
                    try:
                        location_elem = card.find_element(By.CSS_SELECTOR, "div.flex.alignItems.gap-5.darkGrayColor")
                        location = location_elem.text.strip()
                    except:
                        location = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

                    year = extract_year(card_text)
                    mileage = extract_mileage(card_text)
                    condition = extract_condition(card_text)
                    seller_type = extract_seller_type(card)

                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø¨Ø¯Ø¦ÙŠØ§Ù‹
                    model = extract_model_from_card_and_page(card)

                    # Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¥Ù„Ù‰ ØµÙØ­Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„
                    price_text = "N/A"
                    price_num = np.nan
                    fuel_type = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                    insurance = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†"
                    transmission = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                    color = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"

                    if full_link:
                        try:
                            driver.execute_script("window.open(arguments[0]);", full_link)
                            driver.switch_to.window(driver.window_handles[1])
                            time.sleep(2)

                            page_html = driver.page_source
                            model = extract_model_from_card_and_page(card, page_html, driver)

                            if year == "N/A":
                                year = extract_year(driver.find_element(By.TAG_NAME, "body").text)

                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¹Ø±
                            price_text, price_num = extract_price_from_page(driver)

                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„ÙˆÙ‚ÙˆØ¯
                            fuel_type = extract_fuel_type_advanced(driver)

                            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ‚Ø³ÙŠØ· Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
                            page_text_full = driver.find_element(By.TAG_NAME, "body").text
                            if is_installment_advanced(price_text, page_text_full, fuel_type, price_num):
                                print(fix_arabic(f"â­ï¸ ØªØ®Ø·ÙŠ Ø¥Ø¹Ù„Ø§Ù† {ad_counter} (ØªÙ‚Ø³ÙŠØ·) - {fuel_type} Ø¨Ø³Ø¹Ø± {price_num}"))
                                driver.close()
                                driver.switch_to.window(driver.window_handles[0])
                                continue

                            # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                            insurance = extract_insurance_from_page(driver)
                            transmission = extract_transmission_from_page(driver)
                            color = extract_color_from_page(driver)

                            driver.close()
                            driver.switch_to.window(driver.window_handles[0])
                        except Exception as e:
                            print(fix_arabic(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ÙØªØ­ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù† {ad_counter}: {e}"))
                            if len(driver.window_handles) > 1:
                                driver.close()
                            driver.switch_to.window(driver.window_handles[0])
                            continue

                    if model == "ØºÙŠØ± Ù…ØªÙˆÙØ±" or not model:
                        model = extract_brand_model_from_text(card_text)

                    all_ads.append({
                        'ID': ad_counter,
                        'Model': model,
                        'Year': year,
                        'Condition': condition,
                        'Fuel Type': fuel_type,
                        'Mileage': mileage,
                        'Seller Type': seller_type,
                        'Location': location,
                        'Price': price_text,
                        'Insurance': insurance,
                        'Transmission': transmission,
                        'Color': color
                    })

                    print(fix_arabic(f"   âœ… {ad_counter}: {model[:50]}... | {price_text} | {fuel_type}"))
                    ad_counter += 1

                except Exception as e:
                    print(fix_arabic(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø¹Ù„Ø§Ù†: {e}"))
                    if len(driver.window_handles) > 1:
                        driver.close()
                        driver.switch_to.window(driver.window_handles[0])
                    continue

            if stop_flag:
                break

            # Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„ØµÙØ­Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            try:
                next_button = driver.find_element(By.CSS_SELECTOR, "a[data-id='nextPageArrow']")
                driver.execute_script("arguments[0].click();", next_button)
                time.sleep(3)
                current_page += 1
            except NoSuchElementException:
                print(fix_arabic("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙØ­Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©."))
                break

        except TimeoutException:
            print(fix_arabic("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©."))
            break
        except Exception as e:
            print(fix_arabic(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}"))
            break

    driver.quit()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡Ø§
    if all_ads:
        df = pd.DataFrame(all_ads)
        df = df[['ID', 'Model', 'Year', 'Condition', 'Fuel Type', 'Mileage', 'Seller Type', 'Location', 'Price', 'Insurance', 'Transmission', 'Color']]

        # Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        arabic_file = "cars_arabic.xlsx"
        df.to_excel(arabic_file, index=False)
        print(fix_arabic(f"\nâœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: {arabic_file}"))

        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø¹ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        print(fix_arabic("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©..."))
        df_en = df.copy()

        # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù†ØµÙŠØ© (Ø¹Ø¯Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„)
        for col in ['Condition', 'Fuel Type', 'Seller Type', 'Location', 'Insurance', 'Transmission', 'Color']:
            df_en[col] = df_en[col].apply(lambda x: translate_text(x))

        # ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        df_en['Model'] = df_en['Model'].apply(lambda x: translate_car_model_smart(x))

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø©
        df_en = df_en.replace(['N/A', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯', 'ØºÙŠØ± Ù…ØªÙˆÙØ±', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ£Ù…ÙŠÙ†'], np.nan)

        # Ù„Ø§ Ù†Ø¶ÙŠÙ ad_id
        kaggle_file = "jordan_cars_kaggle.csv"
        df_en.to_csv(kaggle_file, index=False, encoding='utf-8-sig')
        print(fix_arabic(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†Ø³Ø®Ø© Kaggle: {kaggle_file}"))

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©
        print(fix_arabic("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:"))
        print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª: {len(df_en)}")
        print(f"Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©: {df_en[df_en['Fuel Type'] == 'Electric'].shape[0]}")
        print(f"Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù‡Ø§ÙŠØ¨Ø±Ø¯: {df_en[df_en['Fuel Type'] == 'Hybrid'].shape[0]}")
        print(f"Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ù†Ø²ÙŠÙ†: {df_en[df_en['Fuel Type'] == 'Petrol'].shape[0]}")
        print(f"Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¯ÙŠØ²Ù„: {df_en[df_en['Fuel Type'] == 'Diesel'].shape[0]}")

        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø©
        print(fix_arabic("\nğŸ“‹ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ø£ÙˆÙ„ 5 ØµÙÙˆÙ):"))
        print(df_en[['Model', 'Year', 'Fuel Type', 'Price']].head())

    else:
        print(fix_arabic("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª."))

if __name__ == "__main__":
    main()